{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install pyspark\n",
    "#!conda install findspark\n",
    "#!conda install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| Name|Age|\n",
      "+-----+---+\n",
      "| John| 30|\n",
      "|Alice| 25|\n",
      "|  Bob| 35|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MySparkApp\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Test with a simple DataFrame\n",
    "data = [(\"John\", 30), (\"Alice\", 25), (\"Bob\", 35)]\n",
    "df = spark.createDataFrame(data, [\"Name\", \"Age\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/rzhang/.cache/kagglehub/datasets/microize/newyork-yellow-taxi-trip-data-2020-2019/versions/25\n"
     ]
    }
   ],
   "source": [
    "# Download specific files from the dataset\n",
    "import kagglehub\n",
    "path = \"/Users/rzhang/.cache/kagglehub/datasets/microize/newyork-yellow-taxi-trip-data-2020-2019/versions/25\"\n",
    "# Download the file package, size = 10GB\n",
    "#path = kagglehub.dataset_download(\n",
    "#    \"microize/newyork-yellow-taxi-trip-data-2020-2019\"\n",
    "#)\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=1, tpep_pickup_datetime='2019-06-01 00:55:13', tpep_dropoff_datetime='2019-06-01 00:56:17', passenger_count=1, trip_distance=0.0, RatecodeID=1, store_and_fwd_flag='N', PULocationID=145, DOLocationID=145, payment_type=2, fare_amount=3.0, extra=0.5, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, improvement_surcharge=0.3, total_amount=4.3, congestion_surcharge=0.0),\n",
       " Row(VendorID=1, tpep_pickup_datetime='2019-06-01 00:06:31', tpep_dropoff_datetime='2019-06-01 00:06:52', passenger_count=1, trip_distance=0.0, RatecodeID=1, store_and_fwd_flag='N', PULocationID=262, DOLocationID=263, payment_type=2, fare_amount=2.5, extra=3.0, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, improvement_surcharge=0.3, total_amount=6.3, congestion_surcharge=2.5),\n",
       " Row(VendorID=1, tpep_pickup_datetime='2019-06-01 00:17:05', tpep_dropoff_datetime='2019-06-01 00:36:38', passenger_count=1, trip_distance=4.4, RatecodeID=1, store_and_fwd_flag='N', PULocationID=74, DOLocationID=7, payment_type=2, fare_amount=17.5, extra=0.5, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, improvement_surcharge=0.3, total_amount=18.8, congestion_surcharge=0.0),\n",
       " Row(VendorID=1, tpep_pickup_datetime='2019-06-01 00:59:02', tpep_dropoff_datetime='2019-06-01 00:59:12', passenger_count=0, trip_distance=0.8, RatecodeID=1, store_and_fwd_flag='N', PULocationID=145, DOLocationID=145, payment_type=2, fare_amount=2.5, extra=1.0, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, improvement_surcharge=0.3, total_amount=4.3, congestion_surcharge=0.0),\n",
       " Row(VendorID=1, tpep_pickup_datetime='2019-06-01 00:03:25', tpep_dropoff_datetime='2019-06-01 00:15:42', passenger_count=1, trip_distance=1.7, RatecodeID=1, store_and_fwd_flag='N', PULocationID=113, DOLocationID=148, payment_type=1, fare_amount=9.5, extra=3.0, mta_tax=0.5, tip_amount=2.65, tolls_amount=0.0, improvement_surcharge=0.3, total_amount=15.95, congestion_surcharge=2.5)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv(path + \"/yellow_tripdata_2019-06.csv\", header=True, inferSchema=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'tpep_pickup_datetime',\n",
       " 'tpep_dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'RatecodeID',\n",
       " 'store_and_fwd_flag',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print all columns\n",
    "df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Column Name:\n",
    " \n",
    " 1. 'VendorID'  TPEP Provider ID 1 or 2, not used in this project\n",
    " 2. 'tpep_pickup_datetime'  Pickup date and time\n",
    " 3. 'tpep_dropoff_datetime'  Dropoff date and time\n",
    " 4. 'passenger_count'  Number of passengers\n",
    " 5. 'trip_distance'  Trip distance in miles\n",
    " 6. 'RatecodeID'  Rate code ID: 1=Standard rate, 2=JFK, 3=Newark, 4=Nassau or Westchester, 5=Negotiated fare, 6=Group ride\n",
    " 7. 'store_and_fwd_flag'  Store and forward flag, not used in this project\n",
    " 8. 'PULocationID'  Pickup location ID\n",
    " 9. 'DOLocationID'  Dropoff location ID\n",
    " 10. 'payment_type'  Payment type: 1=Credit card, 2=Cash, 3=No charge, 4=Dispute, 5=Unknown, 6=Voided trip\n",
    " 11. 'fare_amount'  Fare amount\n",
    " 12. 'extra'  Extra charges\n",
    " 13. 'mta_tax'  MTA tax\n",
    " 14. 'tip_amount'  Tip amount\n",
    " 15. 'tolls_amount'  Tolls amount\n",
    " 16. 'improvement_surcharge'  Improvement surcharge\n",
    " 17. 'total_amount'  Total amount\n",
    " 18. 'congestion_surcharge'  Congestion surcharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n",
      "Number of rows: 6941024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+---------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+---------------------+------------------+--------------------+\n",
      "|summary|          VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|   passenger_count|     trip_distance|        RatecodeID|store_and_fwd_flag|      PULocationID|      DOLocationID|      payment_type|       fare_amount|             extra|            mta_tax|        tip_amount|       tolls_amount|improvement_surcharge|      total_amount|congestion_surcharge|\n",
      "+-------+------------------+--------------------+---------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+---------------------+------------------+--------------------+\n",
      "|  count|           6941024|             6941024|              6941024|           6941024|           6941024|           6941024|           6941024|           6941024|           6941024|           6941024|           6941024|           6941024|            6941024|           6941024|            6941024|              6941024|           6941024|             6941024|\n",
      "|   mean|1.6425458260913663|                null|                 null|1.5673220550742946|3.0785054986122593| 1.059386194313692|              null|162.30344384344443|160.82040301258144|1.2920401946456315|13.664141345714874|1.1646519749823667|0.49500102290382525|2.2659335711858337|0.40619765181600836|   0.2984860447057198|19.741270665683032|  2.2744667069296978|\n",
      "| stddev|0.5018739369760152|                null|                 null|1.2108313793987653| 17.90047923155899|0.7349946880878757|              null| 66.38413261067763| 70.46477633717038|0.4809936447831745| 132.3297330755027|1.2753448849313533|0.10085133569674189| 2.962398367544557| 1.7975054433986337| 0.028545118711108753|132.67980566204378|  0.7289606350313826|\n",
      "|    min|                 1| 2001-01-01 00:02:08|  2001-01-01 01:00:02|                 0|               0.0|                 1|                 N|                 1|                 1|                 1|            -305.0|             -26.5|               -0.5|            -88.88|             -39.74|                 -0.3|            -305.8|                -2.5|\n",
      "|    max|                 4| 2019-10-30 10:20:13|  2019-10-30 10:30:26|                 9|          45977.22|                99|                 Y|               265|               265|                 4|         346949.99|             84.76|             212.42|           1624.64|              823.0|                  0.3|         347035.05|                2.75|\n",
      "+-------+------------------+--------------------+---------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+---------------------+------------------+--------------------+\n",
      "\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|       1| 2019-06-01 00:55:13|  2019-06-01 00:56:17|              1|          0.0|         1|                 N|         145|         145|           2|        3.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         4.3|                 0.0|\n",
      "|       1| 2019-06-01 00:06:31|  2019-06-01 00:06:52|              1|          0.0|         1|                 N|         262|         263|           2|        2.5|  3.0|    0.5|       0.0|         0.0|                  0.3|         6.3|                 2.5|\n",
      "|       1| 2019-06-01 00:17:05|  2019-06-01 00:36:38|              1|          4.4|         1|                 N|          74|           7|           2|       17.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        18.8|                 0.0|\n",
      "|       1| 2019-06-01 00:59:02|  2019-06-01 00:59:12|              0|          0.8|         1|                 N|         145|         145|           2|        2.5|  1.0|    0.5|       0.0|         0.0|                  0.3|         4.3|                 0.0|\n",
      "|       1| 2019-06-01 00:03:25|  2019-06-01 00:15:42|              1|          1.7|         1|                 N|         113|         148|           1|        9.5|  3.0|    0.5|      2.65|         0.0|                  0.3|       15.95|                 2.5|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Columns: ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge']\n",
      "VendorID: IntegerType\n",
      "tpep_pickup_datetime: StringType\n",
      "tpep_dropoff_datetime: StringType\n",
      "passenger_count: IntegerType\n",
      "trip_distance: DoubleType\n",
      "RatecodeID: IntegerType\n",
      "store_and_fwd_flag: StringType\n",
      "PULocationID: IntegerType\n",
      "DOLocationID: IntegerType\n",
      "payment_type: IntegerType\n",
      "fare_amount: DoubleType\n",
      "extra: DoubleType\n",
      "mta_tax: DoubleType\n",
      "tip_amount: DoubleType\n",
      "tolls_amount: DoubleType\n",
      "improvement_surcharge: DoubleType\n",
      "total_amount: DoubleType\n",
      "congestion_surcharge: DoubleType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Print the schema (column names and types)\n",
    "df.printSchema()\n",
    "\n",
    "# Get number of rows\n",
    "print(\"Number of rows:\", df.count())\n",
    "\n",
    "# Show basic statistics for numeric columns\n",
    "df.describe().show()\n",
    "\n",
    "# Show the first few rows\n",
    "df.show(5)\n",
    "\n",
    "# Get column names\n",
    "print(\"Columns:\", df.columns)\n",
    "\n",
    "# Get basic data types of columns\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df.schema[col].dataType}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns: ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'PULocationID', 'DOLocationID', 'payment_type', 'total_amount']\n",
      "+--------------------+---------------------+---------------+-------------+----------+------------+------------+------------+------------+\n",
      "|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|PULocationID|DOLocationID|payment_type|total_amount|\n",
      "+--------------------+---------------------+---------------+-------------+----------+------------+------------+------------+------------+\n",
      "| 2019-06-01 00:55:13|  2019-06-01 00:56:17|              1|          0.0|         1|         145|         145|           2|         4.3|\n",
      "| 2019-06-01 00:06:31|  2019-06-01 00:06:52|              1|          0.0|         1|         262|         263|           2|         6.3|\n",
      "| 2019-06-01 00:17:05|  2019-06-01 00:36:38|              1|          4.4|         1|          74|           7|           2|        18.8|\n",
      "| 2019-06-01 00:59:02|  2019-06-01 00:59:12|              0|          0.8|         1|         145|         145|           2|         4.3|\n",
      "| 2019-06-01 00:03:25|  2019-06-01 00:15:42|              1|          1.7|         1|         113|         148|           1|       15.95|\n",
      "+--------------------+---------------------+---------------+-------------+----------+------------+------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop specified columns\n",
    "df_cleaned = df.drop(\n",
    "    'VendorID',\n",
    "    'store_and_fwd_flag',\n",
    "    'fare_amount',\n",
    "    'extra',\n",
    "    'mta_tax',\n",
    "    'tip_amount',\n",
    "    'tolls_amount',\n",
    "    'improvement_surcharge',\n",
    "    'congestion_surcharge'\n",
    ")\n",
    "\n",
    "# Verify the remaining columns\n",
    "print(\"Remaining columns:\", df_cleaned.columns)\n",
    "\n",
    "# Show a few rows of the cleaned dataset\n",
    "df_cleaned.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|LocationID|      Borough|\n",
      "+----------+-------------+\n",
      "|         1|          EWR|\n",
      "|         2|       Queens|\n",
      "|         3|        Bronx|\n",
      "|         4|    Manhattan|\n",
      "|         5|Staten Island|\n",
      "+----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for better machine learning result, replace pullocationID and dolocationID with location name\n",
    "\n",
    "df_zone_name = spark.read.csv('taxi+_zone_lookup.csv', header=True, inferSchema=True)\n",
    "df_zone_name = df_zone_name.drop('Zone', 'service_zone')\n",
    "df_zone_name.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's rename the join columns in df_zone_name to avoid confusion\n",
    "#df_zone_lookup_pu = df_zone_name.withColumnRenamed(\"LocationID\", \"PULocationID\") \\\n",
    "#                            .withColumnRenamed(\"Borough\", \"PULocation\")  \n",
    "# Join for pickup locations\n",
    "#df_with_pu = df_cleaned.join(df_zone_lookup_pu, on=\"PULocationID\", how=\"left\")\n",
    "\n",
    "# Prepare for dropoff location join\n",
    "#df_zone_lookup_do = df_zone_name.withColumnRenamed(\"LocationID\", \"DOLocationID\") \\\n",
    "#                                .withColumnRenamed(\"Borough\", \"DOLocation\")\n",
    "\n",
    "# Join for dropoff locations\n",
    "#df_final = df_with_pu.join(df_zone_lookup_do, on=\"DOLocationID\", how=\"left\")\n",
    "\n",
    "# Drop the original ID columns if you don't need them anymore\n",
    "#df_final = df_final.drop(\"PULocationID\", \"DOLocationID\")\n",
    "\n",
    "# Show the result\n",
    "#df_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+---------------+-------------+----------+---------------+----------------+------------+------------+\n",
      "|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|pickup_location|dropoff_location|payment_type|total_amount|\n",
      "+--------------------+---------------------+---------------+-------------+----------+---------------+----------------+------------+------------+\n",
      "| 2019-06-01 00:55:13|  2019-06-01 00:56:17|              1|          0.0|         1|         Queens|          Queens|           2|         4.3|\n",
      "| 2019-06-01 00:06:31|  2019-06-01 00:06:52|              1|          0.0|         1|      Manhattan|       Manhattan|           2|         6.3|\n",
      "| 2019-06-01 00:17:05|  2019-06-01 00:36:38|              1|          4.4|         1|      Manhattan|          Queens|           2|        18.8|\n",
      "| 2019-06-01 00:59:02|  2019-06-01 00:59:12|              0|          0.8|         1|         Queens|          Queens|           2|         4.3|\n",
      "| 2019-06-01 00:03:25|  2019-06-01 00:15:42|              1|          1.7|         1|      Manhattan|       Manhattan|           1|       15.95|\n",
      "+--------------------+---------------------+---------------+-------------+----------+---------------+----------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. First approach: Using RDD operations (closer to traditional MapReduce)\n",
    "# Convert location mapping to dictionary\n",
    "location_dict = dict(df_zone_name.select(\"LocationID\", \"Borough\").rdd.collect())\n",
    "\n",
    "# Create broadcast variable for the mapping\n",
    "location_broadcast = spark.sparkContext.broadcast(location_dict)\n",
    "\n",
    "# Define map functions\n",
    "def map_locations(row):\n",
    "    locations = location_broadcast.value\n",
    "    # Map both pickup and dropoff locations\n",
    "    pu_location = locations.get(row.PULocationID, \"Unknown\")\n",
    "    do_location = locations.get(row.DOLocationID, \"Unknown\")\n",
    "    \n",
    "    return (\n",
    "        row.tpep_pickup_datetime,\n",
    "        row.tpep_dropoff_datetime,\n",
    "        row.passenger_count,\n",
    "        row.trip_distance,\n",
    "        row.RatecodeID,\n",
    "        pu_location,  # Replaced PULocationID\n",
    "        do_location,  # Replaced DOLocationID\n",
    "        row.payment_type,\n",
    "        row.total_amount\n",
    "    )\n",
    "\n",
    "# Apply the transformation\n",
    "\n",
    "# 1. Convert DataFrame to RDD\n",
    "rdd = df_cleaned.rdd\n",
    "\n",
    "# 2. Apply the mapping function\n",
    "mapped_rdd = rdd.map(map_locations)\n",
    "\n",
    "# 3. Define the schema (column names for the new DataFrame)\n",
    "new_column_names = [\n",
    "    'tpep_pickup_datetime',\n",
    "    'tpep_dropoff_datetime',\n",
    "    'passenger_count',\n",
    "    'trip_distance',\n",
    "    'RatecodeID',\n",
    "    'pickup_location',\n",
    "    'dropoff_location',\n",
    "    'payment_type',\n",
    "    'total_amount'\n",
    "]\n",
    "\n",
    "# 4. Convert back to DataFrame with the new schema\n",
    "df_mapped = mapped_rdd.toDF(new_column_names)\n",
    "\n",
    "# Show results\n",
    "df_mapped.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------------+------------+---------------+-------------+----------+---------------+----------------+------------+------------+\n",
      "|pickup_date|pickup_hour|dropoff_date|dropoff_hour|passenger_count|trip_distance|RatecodeID|pickup_location|dropoff_location|payment_type|total_amount|\n",
      "+-----------+-----------+------------+------------+---------------+-------------+----------+---------------+----------------+------------+------------+\n",
      "| 2019-06-01|          0|  2019-06-01|           0|              1|          0.0|         1|         Queens|          Queens|           2|         4.3|\n",
      "| 2019-06-01|          0|  2019-06-01|           0|              1|          0.0|         1|      Manhattan|       Manhattan|           2|         6.3|\n",
      "| 2019-06-01|          0|  2019-06-01|           0|              1|          4.4|         1|      Manhattan|          Queens|           2|        18.8|\n",
      "| 2019-06-01|          0|  2019-06-01|           0|              0|          0.8|         1|         Queens|          Queens|           2|         4.3|\n",
      "| 2019-06-01|          0|  2019-06-01|           0|              1|          1.7|         1|      Manhattan|       Manhattan|           1|       15.95|\n",
      "+-----------+-----------+------------+------------+---------------+-------------+----------+---------------+----------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import hour, to_date\n",
    "\n",
    "# Create new DataFrame with extracted date and hour\n",
    "df_time_processed = df_mapped \\\n",
    "    .withColumn('pickup_date', to_date('tpep_pickup_datetime')) \\\n",
    "    .withColumn('pickup_hour', hour('tpep_pickup_datetime')) \\\n",
    "    .withColumn('dropoff_date', to_date('tpep_dropoff_datetime')) \\\n",
    "    .withColumn('dropoff_hour', hour('tpep_dropoff_datetime')) \\\n",
    "    .drop('tpep_pickup_datetime', 'tpep_dropoff_datetime')\n",
    "\n",
    "# Reorder columns for better readability\n",
    "columns_order = [\n",
    "    'pickup_date',\n",
    "    'pickup_hour',\n",
    "    'dropoff_date',\n",
    "    'dropoff_hour',\n",
    "    'passenger_count',\n",
    "    'trip_distance',\n",
    "    'RatecodeID',\n",
    "    'pickup_location',\n",
    "    'dropoff_location',\n",
    "    'payment_type',\n",
    "    'total_amount'\n",
    "]\n",
    "\n",
    "df_time_processed = df_time_processed.select(columns_order)\n",
    "\n",
    "# Show the result\n",
    "df_time_processed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-----------+------------+-------------------+------------+---------------+-------------+----------+---------------+----------------+------------+------------+\n",
      "|pickup_date|pickup_day_of_week|pickup_hour|dropoff_date|dropoff_day_of_week|dropoff_hour|passenger_count|trip_distance|RatecodeID|pickup_location|dropoff_location|payment_type|total_amount|\n",
      "+-----------+------------------+-----------+------------+-------------------+------------+---------------+-------------+----------+---------------+----------------+------------+------------+\n",
      "| 2019-06-01|          Saturday|          0|  2019-06-01|           Saturday|           0|              1|          0.0|         1|         Queens|          Queens|           2|         4.3|\n",
      "| 2019-06-01|          Saturday|          0|  2019-06-01|           Saturday|           0|              1|          0.0|         1|      Manhattan|       Manhattan|           2|         6.3|\n",
      "| 2019-06-01|          Saturday|          0|  2019-06-01|           Saturday|           0|              1|          4.4|         1|      Manhattan|          Queens|           2|        18.8|\n",
      "| 2019-06-01|          Saturday|          0|  2019-06-01|           Saturday|           0|              0|          0.8|         1|         Queens|          Queens|           2|         4.3|\n",
      "| 2019-06-01|          Saturday|          0|  2019-06-01|           Saturday|           0|              1|          1.7|         1|      Manhattan|       Manhattan|           1|       15.95|\n",
      "+-----------+------------------+-----------+------------+-------------------+------------+---------------+-------------+----------+---------------+----------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import date_format, dayofweek\n",
    "\n",
    "# Add day of week (1 = Sunday, 7 = Saturday)\n",
    "df_with_dow = df_time_processed \\\n",
    "    .withColumn('pickup_day_of_week', date_format('pickup_date', 'EEEE')) \\\n",
    "    .withColumn('dropoff_day_of_week', date_format('dropoff_date', 'EEEE'))\n",
    "\n",
    "\n",
    "\n",
    "# Reorder columns\n",
    "columns_order = [\n",
    "    'pickup_date',\n",
    "    'pickup_day_of_week',\n",
    "    'pickup_hour',\n",
    "    'dropoff_date',\n",
    "    'dropoff_day_of_week',\n",
    "    'dropoff_hour',\n",
    "    'passenger_count',\n",
    "    'trip_distance',\n",
    "    'RatecodeID',\n",
    "    'pickup_location',\n",
    "    'dropoff_location',\n",
    "    'payment_type',\n",
    "    'total_amount'\n",
    "]\n",
    "\n",
    "df_with_dow = df_with_dow.select(columns_order)\n",
    "\n",
    "# Show the result\n",
    "df_with_dow.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common pickup-dropoff location pairs:\n",
      "+----------------------+---------+\n",
      "|location_pair         |frequency|\n",
      "+----------------------+---------+\n",
      "|{Manhattan, Manhattan}|5808188  |\n",
      "|{Queens, Manhattan}   |264493   |\n",
      "|{Manhattan, Queens}   |223738   |\n",
      "|{Manhattan, Brooklyn} |169540   |\n",
      "|{Queens, Queens}      |159312   |\n",
      "|{Queens, Brooklyn}    |64623    |\n",
      "|{Brooklyn, Brooklyn}  |52725    |\n",
      "|{Unknown, Unknown}    |51228    |\n",
      "|{Manhattan, Bronx}    |33403    |\n",
      "|{Brooklyn, Manhattan} |25142    |\n",
      "+----------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "Total unique location pairs: 46\n"
     ]
    }
   ],
   "source": [
    "# 1. Convert DataFrame to RDD and map to (location_pair, 1) format\n",
    "location_pairs_rdd = df_with_dow.rdd.map(\n",
    "    lambda row: (\n",
    "        (row.pickup_location, row.dropoff_location), \n",
    "        1\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2. Reduce by key (location pair) to sum frequencies\n",
    "location_pairs_count = location_pairs_rdd.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# 3. Sort by frequency in descending order\n",
    "# FIXED: Changed sortByKey to sortBy and added proper sorting function\n",
    "sorted_pairs = location_pairs_count.sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "# 4. Convert back to DataFrame for better display\n",
    "result_df = sorted_pairs.toDF(['location_pair', 'frequency'])\n",
    "\n",
    "# 5. Show top results\n",
    "print(\"Most common pickup-dropoff location pairs:\")\n",
    "result_df.show(10, truncate=False)\n",
    "\n",
    "# Optional: Get total number of unique pairs\n",
    "print(\"\\nTotal unique location pairs:\", result_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
